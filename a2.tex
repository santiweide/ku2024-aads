\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{upquote}
\usepackage[margin=1in]{geometry} 
\usepackage{amsmath,amsthm,amssymb}
\usepackage{graphicx}
\usepackage{listings}
\newenvironment{statement}[2][Statement]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\usepackage{xcolor}




\title{Assignment 2}


\author{Author \\
  Wanjing Hu / fng685@alumni.ku.dk  \\
  Zhigao Yan / sxd343@alumni.ku.dk  \\
  Wenshuo Dong / gnj461@alumni.ku.dk  \\
  Jiayi Zhang / xrw579@alumni.ku.dk \\
} 
 

\begin{document}
\maketitle

\section{29.1-9}
% wenshuo 
\[
\begin{aligned}
maximize& \\
& z = 3x_1 + 2x_2 \\
subject \, to&  \\
& x_1 - x_2 \leq 66, \\ 
& x_1 + x_2 \geq 77,\\
& x_1, x_2 \geq 0.
\end{aligned}
\]

The feasible region is unbounded because there is no constraint explicitly limiting \(x_1\) and \(x_2\) from growing indefinitely in certain directions.
For example, \(x_1 \to \infty\) and \(x_2 \to \infty\) is possible as long as the constraints are satisfied.

Despite the feasible region being unbounded, the objective function \(z = 3x_1 + 2x_2\) does not increase indefinitely. The key limiting constraint is \(x_1 - x_2 \leq 66\), which ensures that \(x_1\) and \(x_2\) cannot grow disproportionately. The optimal value occurs where the constraints intersect.
\section{29.2-3}
% jiayi
\textbf{Question:}
In the single-source shortest-paths problem, we want to find the shortest-path weights from a source vertex $s$ to all vertices $v \in V $. Given a graph $G$, write a linear program for which the solution has the property that $d_{v}$ is the shortest-path weight from $s$ to $v$ for each vertex $v \in V$.

\textbf{Answer:}
To get the shortest-path weight from $s$ to $v$ for each vertex $v \in V$, the linear program will be:
\begin{equation}
\begin{aligned}
maximize& \\
& \sum_{v \in V} d_{v}\\
subject \, to&  \\
& d_{v} <=  d_{v} + w(v, u)\, for \, each \, u,v \in \{E\} \\
& d_{s} = 0
\end{aligned}
\end{equation}
The constraints are Similar to the shortest-path problem with only one destination $t$, the first constraint line ensures the path is correct while the second one gives a initial state of the problem.


\section{29.2-6}
% wanjing
\textbf{Question:}
Write a linear program that, given a bipartite graph $G = (V,E)$, solves the maximum-bipartite matching problem.

\textbf{Answer}

Let $V = L \cup R$, $L \cap R = \emptyset$ . Then make a new vertex for the source which has an edge of unit capacity going to each of the vertices in $L$, and a new vertex for sink which has an edge from each of the vertices in $R$, and we have a new graph $G'=(V',E')$, where $V' = V \cup \{s,t\}$, $E' = E \cup \{s, t\}$. The capacity of edges going out of $s$ and going into $t$ are all 1. Also every original edge from left to right are edges with capacity 1.

First we need to prove the finding maximum-bipartite matching $M$ in the original bipartite graph $G$ is equivalent to finding the max flow in the graph $G$. The proof is as follows:

We first show that a matching $M$ in $G$ corresponds to an integer valued flow $f$ in $G'$. Define $f$ as follows: If $(u,v) \in M$, then $f(s,u) = f(u,v) = f(v,t) = 1$. For all other edges $(u,v) \in E'$, we define $f(u,v) = 0$. Then we have $f$ satisfying both the capacity constraint and the flow conservation.

Next, we can see each edge $(u,v) \in M$ corresponse to one unit flow in $G'$ that traverses the path $s \rightarrow u \rightarrow v \rightarrow t$. Moreover, the paths induced by edges in $M$ are vertext-disjoint, except for $s$ and $t$. The net flow across cut $(L \cup \{s\}, R \cup \{t\})$ is equal to $|M|$. thus the value of the flow $|f| = M$. 

Then we also need to prove $|M| = |f|$ in the converse side. Let $f$ be an integer-valued flow in $G'$ and let $M = \{(u,v): u \in L,\, v \in R,\, and\, f(u,v) >0\}$.

By flow conservation, each $u \in L$ has at most one unit of flow entering the edge $(s,u)$, and since $f$ is integer valued, for each $u \in L$, the one unit of flow can enter on at most one edge and can leave on at most one edge. Then one unit of flpw enters $u$ if and only if there is exactly one vertex $v \in R$ such that $f(u,v) = 1$, and at most one edge leaving each $u \in L$ carries positive flow. A symmetric proof can be made for each $v \in R$ Thus the set M is a matching.

Then the linear programming problem could be defined as follows:

\begin{equation}
\begin{aligned}
maximize& \\
& \sum_{v \in L} f_{(s,v)}\\
subject \, to&  \\
& f_{(u,v)} <=1 \, for \, each \, u,v \in \{s\} \cup L \cup R \cup \{t\} = V\\ 
& \sum_{v \in V} f_{(v,u)} = \sum_{v \in V} f_{(u,v)} \, for \, each \, u \in L \cup R\\
&f_{(u,v)} >= 0 \, for \,each \, u,v \in V
\end{aligned}
\end{equation}


\section{29.4-3}
% zhigao
\textbf{Question:}
Write down the dual of the maximum-flow linear program, as given in lines
(29.47)â€“(29.50) on page 860. Explain how to interpret this formulation as a
minimum-cut problem.\\
\textbf{Answer:}
Firstly, I need to convert the original formulas to standard form.
We can set a coefficient C that is 1 when \(u=s\) and -1 when \(v=s\).
\[
\begin{aligned}
maximize& \\
&\sum_{u,v \in V} Cfuv, \\
subject \, to& \\
&f_{uv} \leq c(u, v), \quad \text{for each } u, v \in V, \\
&\sum_{v \in V} f_{vu} = \sum_{v \in V} f_{uv}, \quad \text{for each } u \in V \setminus \{s, t\}, \\
&f_{uv} \geq 0, \quad \text{for each } u, v \in V.
\end{aligned}
\]
The second formula can be changed to 
\[
\sum_{v \in V} f_{vu} - \sum_{v \in V} f_{uv} \leq 0 \quad \text{for each } u \in V \setminus \{s, t\}
\]
\[-\sum_{v \in V} f_{vu} + \sum_{v \in V} f_{uv} \leq 0\ \quad \text{for each } u \in V \setminus \{s, t\}\]
Now we can get the dual subject function by the subject function, for capacity constraints and flow conservation, \(y_{uv}\), \(y_u\)(flow conservation for \(u\)) and \(y_v\)(flow conservation for \(v\))can be introduced, 

\[y_{uv}-y_u+y_v \geq C \quad \text{for each } u, v \in V\]
We can split this equation into:
\[y_{uv}-y_u+y_v \geq 0 \quad \text{for each } u, v \in V\setminus \{s, t\}\]
\[y_{sv}+y_v \geq 1 \quad \text{for each } v \in V\setminus \{s\}\]
\[y_{us}-y_u \geq -1 \quad \text{for each } u \in V\setminus \{s\}\]
\[y_{uv} \geq 0, \quad y_u \geq 0,\quad y_v\geq 0\]
The final object function is :
\[minimize \quad \sum_{u,v \in V} c(u,v)y_{uv}\]
From the object function, we can set \(y_{uv}\) as the variable for every edge, if one edge has been "cut", we need to add the capacity to the result. We can also think of \(y_u\) as the attribution of each point(without s and t). These constraints are to ensure that if two points belong to different sets, then edge \(uv\) must be cut.




\section{Linear Programming - B}
\textbf{Question:}
Write an LP in standard form in the plane so that: (1) the feasible region is a convex polygon with 5 edges, (2) the maximum of the LP is 1 and (3) the maximum is achieved on a full edge of the feasible region (and not just a single vertex)\\
% wenshuo
\textbf{Answer:}

\[
\begin{aligned}
Maximize& \\
&z = x_1, \\
Subject \, to& \\
& \quad x_1 + x_2 \leq \sqrt{2}, \\
& \quad x_1 - x_2 \leq \sqrt{2}, \\
& \quad -x_1 + x_2 \leq \sqrt{2}, \\
& \quad -x_1 - x_2 \leq \sqrt{2}, \\
& \quad x_1 \leq 1.
\end{aligned}
\]
\section{Linear Programming - C}
\textbf{Question}
This exercise demonstrates that LP can represent non-linearities (like absolute values). Let f be a function from the set {1,2} to the real numbers. 

Write an LP whose value is $|f(1)|+|f(2)|$, and write the dual to this LP. In your solutions, all the entries in the matrix A and in the vectors b,c must be affine functions in $f(1)$ and $f(2)$; that is, each entry must be of the form $d f(1) + e f(2) + g$ where $d$,$e$,$g$ are real numbers. For example, in dimension n = 3, the vector b can be $(3 f(1), 0, -2f(2)+1)$ but not $(|f(1)|,0,0)$. \\
% jiayi
\textbf{Answer:}
To express the absolute value  $|f(1)|$ and $|f(2)|$,  we import $x$ and $y$ where $x  \geq|f(1)|$ and $y  \geq|f(2)|$ , so the corresponding constraints are: $x \geq f(1), x \geq -f(1), y \geq f(2), y \geq -f(2)$.\\
For convenience, the objective function will be defined as:
$z = x + y$ and the final question will be convert to:\\
\begin{equation}
\begin{aligned}
minimize& \\
& z = x + y\\
subject \, to&  \\
& x \geq f(1)\\
& x \geq -f(1)\\
& y \geq f(2)\\
& y \geq -f(2)\\
& x\geq 0, y \geq 0\\
\end{aligned}
\end{equation}

To get the dual to the LP,  the minimize need to be convert to the maximize, and $Ax \geq b$ also need to be convert to $A^Ty \leq c$.

The dual is:
\begin{equation}
\begin{aligned}
maximize& \\
& z = f(1)(y_{1} - y_{2}) + f(2)(y_{3} - y_{4}) \\
subject \, to&  \\
& y_{1} + y_{2} \leq 1\\
& y_{3} + y_{4} \leq 1\\
& y_{i}\geq 0, 1\leq y \leq 4\\
\end{aligned}
\end{equation}

\section{Randomized Algorithm-1}
\textbf{Question}
For any given key $x$ in $S$, let $d(x)$ be the depth of $x$ in the search tree generated by $RandQS$. Give a lower and an upper bound, as a function of the number of keys n, on the expected value of $d(x)$ such that these bounds are within a constant factor from each other. That is, find a function $f(n)$ and prove that $E[d(x)]=\Theta(f(n))$.

% wanjing
\textbf{Answer}
Whenever an element is compared its depth will increase. So the depth of element $x$, $d(x)$ is equivalent to the number of times x is compared until it becomes a pivot or no longer participates in the subproblem. So the $E[d(x)]$ is the same as $E(A)$ where $A$ stands for the case when $x$ is chosen as the pivot, thus the sum counting of how many times $x$ is compared. \\

Let $[S_{(1)}, ..., S_{(n)}] := RandQS(S)$. 

Let $Xij$ be the number of times that $S_{(i)}$ and $x$ are compared, where $x:=S_{(j)}$. Also let $p_{ij}$ be the probability of this event.

\begin{equation}
\begin{aligned}
E[d(x)] &= E[\#comparisons] \\
&= E[\sum_{i<j} X_{ij}]\\
&=\sum_{i<j} E[X_{ij}]\\
&=\sum_{i<j} Pr[X_{ij} = x] * x\\
&= \sum_{i<j}  (1-p_{ij}) * 0 + p_{ij} * 1\\
&=  \sum_{i<j} p_{ij}
\end{aligned}
\end{equation}

From the Lemma of: $S_{(i)}$ and $S_{(j)}$ are compared iff $S_{(i)}$ or $S_{(j)}$ is the first of $S_{(i)}, ..., S_{(j)}$ to be chosen as a pivot, we can see $p_{ij}$ is the conditional probability of picking $S_{(i)}$ or $S_{(j)}$
 given that the pivot is picked uniformly at random in $\{S_{(i)}, ..., S_{(j)}\}$. So $p_{ij} = \frac{2}{j+1-i}$.
 
 Then 
\begin{equation}
\begin{aligned}
E[d(x)] &=  \sum_{i<j} p_{ij} \\
&=  \sum_{i<j}  \frac{2}{j+1-i}\\
&= \sum_{i=1}^{n-1} \sum_{j=i+1}^{n}  \frac{2}{j+1-i}\\
&= \sum_{i=1}^{n-1} \sum_{k=2}^{n+1-i}  \frac{2}{k}\\
&= 2*n*\sum_{k=2}^{ni}  \frac{2}{k}\\
&= 2*n*(\sum_{k=1}^{n}  \frac{2}{k}-1)\\
&=2*n*(H_{n}-1)\\
&\leq 2*n* \int_{1}^{n} \frac{1}{x} dx \\
&\in O(nlogn)
\end{aligned}
\end{equation}

So $f(n)= nlogn$
\section{Randomized Algorithm-2}
\textbf{Question}
How many runs of randomized contraction do we need to be 99\% sure that a minimum cut is found?
% zhigao
\textbf{Answer}:
Every time we run the randomized contraction, the probability of min-cut is returned is (n is the number of vectors in the graph):
\[P\geq\frac{2}{n(n-1)}\]
So the probability of min-cut is not returned is :
\[P\geq1-\frac{2}{n(n-1)}\]
By t times, this probability is :
\[(1-\frac{2}{n(n-1)})^t\]
We want to ensure 99\% that a minimum cut is found, Hence:
\[(1-\frac{2}{n(n-1)})^t\leq0.01\]
\[=tln(1-\frac{2}{n(n-1)})\leq ln(0.01)\]
\[=t\leq \frac{ln(0.01)}{ln(1-\frac{2}{n(n-1)})}\]
By using the \(1+x\leq e^x \rightarrow ln(1+x)\leq x\), we get:
\[=t\leq \frac{ln(0.01)}{-\frac{2}{n(n-1)}}\]
Finally, If we want to guarantee more than 99\% probability, then the number of times \(t\) needs to satisfy the following condition.
\[
t \geq \frac{4.605 \cdot n(n - 1)}{2}.
\]


\section{Randomized Algorithm-exercises 1.2}
% wenshuo
\textbf{Question:}
Suppose that at each step of our min-cut algorithm, instead of choosing a random edae for contraction we choose two vertices at random and coalesce them into a single vertex. Show that there are inputs on which the probability that this modified algorithm finds a min-cut is exponentially small.\\
\textbf{Answer:}
Consider a complete graph \( K_n \) with \( n \) vertices, where each pair of vertices is connected by an edge. In this graph, the minimum cut consists of all edges incident to a single vertex, and the size of the minimum cut is \( n-1 \). Initially, the graph has \( n \) vertices and \( \binom{n}{2} \) edges. Each vertex corresponds to a valid minimum cut. When two vertices \( u \) and \( v \) are randomly chosen and merged, all edges between \( u \) and \( v \) are eliminated. If \( u \) or \( v \) belongs to the same vertex set defining a minimum cut, that cut is destroyed. The probability of not disrupting a specific minimum cut at any given step depends on the choice of \( u \) and \( v \). However, since the algorithm does not explicitly consider edges, it does not systematically preserve cuts. As the graph is reduced to fewer vertices, the number of remaining cuts shrinks, and the probability of preserving any specific minimum cut decreases. By the time the graph is reduced to 2 vertices, the probability of maintaining any specific minimum cut is exponentially small. Consequently, the overall probability of success is exponentially small as \( n \) increases.

\textbf{Another Answer:}
We still apply Karger's randomize algorithm and pick random two vertices each time, named $(u,v)$. We follow the rules:

If there is an edge between $u$ and $v$, we shrink the edge;

If there is no edge between $u$, $v$, we select again. \\
Still we want to compute the possibility that $RANDMINCUT(G)$ returns a min-cut.\\
Let $P_i$ be the event of not choosing (u,v) as an edge of the mincut at the $i-th$ operation.\\
At the $i-th$ operation, the vertices number is $n-i+1$, and let $c=|S||T|$ , then\\

\begin{equation}
\begin{aligned}
P_i = 1 - \frac{2c}{(n-i+1)(n-i)}
\end{aligned}
\end{equation}

It takes n-2 times to shrink in the randomize algorithm, until there are only two vertices left. So we have

\begin{equation}
\begin{aligned}
P_{mincut} &= \prod_{i=1}^{n-2} (1 - \frac{2c}{(n-i+1)(n-i)})\\
&\approx  \prod_{i=1}^{n-2} (1 - \frac{2c}{n^2})\\
ln(P_{mincut}) &= \sum_{i=1}^{n-2} (1 - \frac{2c}{n^2})\\
&\approx  \frac{2c}{n^2} * (n-2)\\
&= -\frac{2c}{n}
\end{aligned}
\end{equation}

Thus:
\begin{equation}
\begin{aligned}
P_{mincut} &\approx  e^{-\frac{2c}{n}}
\end{aligned}
\end{equation}


\section{Randomized Algorithm-exercises 1.3}
%you may assume that T(n) is the worst case running time of A.
% jiayi
\textbf{Question:}
Exercise 1.3: Consider a Monte Carlo algorithm $A$ for a problem $\Pi$ whose expected running time is at most $T(n)$ on any instance of size $n$ and that produces a correct solution with probability $\gamma(n)$. Suppose further that given a solution to $\Pi$, we can verify its correctness in time $t(n)$. Show how to obtain a Las Vegas algorithm that always gives a correct answer to $\Pi$ and runs in expected time at most $(T(n) + t(n))/\gamma(n)$.\\
\textbf{Answer:}
To convert the Monte Carlo algorithm which may get a wrong answer in a fixed time to a Las Vegas algorithm which always get the correct answer in a uncertain time period, we need to verify the correctness and retry the Monte Carlo algorithm until we get the correct answer.\\
For every time we run the Monte Carlo algorithm and verify the answer, it need $T(n) + t(n)$ time and the probability that the answer is correct is $\gamma(n)$. So according to the property of geometrically distributed, the final expected time that the Las Vegas algorithm get the correct answer to $\Pi$ will be $(T(n) + t(n))/\gamma(n)$.
\end{document}
