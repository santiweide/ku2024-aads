\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{upquote}
\usepackage[margin=1in]{geometry} 
\usepackage{amsmath,amsthm,amssymb}
\usepackage{graphicx}
\usepackage{listings}
\newenvironment{statement}[2][Statement]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\usepackage{xcolor}




\title{Assignment 2}


\author{Author \\
  Wanjing Hu / fng685@alumni.ku.dk  \\
  Zhigao Yan / sxd343@alumni.ku.dk  \\
  Wenshuo Dong / gnj461@alumni.ku.dk  \\
  Jiayi Zhang / xrw579@alumni.ku.dk \\
} 
 

\begin{document}
\maketitle

\section{29.1-9}
% wenshuo 
\[
\begin{aligned}
maximize& \\
& z = 3x_1 + 2x_2 \\
subject \, to&  \\
& x_1 - x_2 \leq 66, \\ 
& x_1 + x_2 \geq 77,\\
& x_1, x_2 \geq 0.
\end{aligned}
\]

The feasible region is unbounded because there is no constraint explicitly limiting \(x_1\) and \(x_2\) from growing indefinitely in certain directions.
For example, \(x_1 \to \infty\) and \(x_2 \to \infty\) is possible as long as the constraints are satisfied.

Despite the feasible region being unbounded, the objective function \(z = 3x_1 + 2x_2\) does not increase indefinitely. The key limiting constraint is \(x_1 - x_2 \leq 66\), which ensures that \(x_1\) and \(x_2\) cannot grow disproportionately. The optimal value occurs where the constraints intersect.
\section{29.2-3}
% jiayi
\textbf{Question:}
In the single-source shortest-paths problem, we want to find the shortest-path weights from a source vertex $s$ to all vertices $v \in V $. Given a graph $G$, write a linear program for which the solution has the property that $d_{v}$ is the shortest-path weight from $s$ to $v$ for each vertex $v \in V$.

\textbf{Answer:}
To get the shortest-path weight from $s$ to $v$ for each vertex $v \in V$, the linear program will be:
\begin{equation}
\begin{aligned}
maximize& \\
& \sum_{v \in V} d_{v}\\
subject \, to&  \\
& d_{v} <=  d_{v} + w(v, u)\, for \, each \, u,v \in \{E\} \\
& d_{s} = 0
\end{aligned}
\end{equation}
The constraints are Similar to the shortest-path problem with only one destination $t$, the first constraint line ensures the path is correct while the second one gives a initial state of the problem.


\section{29.2-6}
% wanjing
\textbf{Question:}
Write a linear program that, given a bipartite graph $G = (V,E)$, solves the maximum-bipartite matching problem.

\textbf{Answer}

Let $V = L \cup R$, $L \cap R = \emptyset$ . Then make a new vertex for the source which has an edge of unit capacity going to each of the vertices in $L$, and a new vertex for sink which has an edge from each of the vertices in $R$, and we have a new graph $G'=(V',E')$, where $V' = V \cup \{s,t\}$, $E' = E \cup \{s, t\}$. The capacity of edges going out of $s$ and going into $t$ are all 1. Also every original edge from left to right are edges with capacity 1.

First we need to prove the finding maximum-bipartite matching $M$ in the original bipartite graph $G$ is equivalent to finding the max flow in the graph $G$. The proof is as follows:

We first show that a matching $M$ in $G$ corresponds to an integer valued flow $f$ in $G'$. Define $f$ as follows: If $(u,v) \in M$, then $f(s,u) = f(u,v) = f(v,t) = 1$. For all other edges $(u,v) \in E'$, we define $f(u,v) = 0$. Then we have $f$ satisfying both the capacity constraint and the flow conservation.

Next, we can see each edge $(u,v) \in M$ corresponse to one unit flow in $G'$ that traverses the path $s \rightarrow u \rightarrow v \rightarrow t$. Moreover, the paths induced by edges in $M$ are vertext-disjoint, except for $s$ and $t$. The net flow across cut $(L \cup \{s\}, R \cup \{t\})$ is equal to $|M|$. thus the value of the flow $|f| = M$. 

Then we also need to prove $|M| = |f|$ in the converse side. Let $f$ be an integer-valued flow in $G'$ and let $M = \{(u,v): u \in L,\, v \in R,\, and\, f(u,v) >0\}$.

By flow conservation, each $u \in L$ has at most one unit of flow entering the edge $(s,u)$, and since $f$ is integer valued, for each $u \in L$, the one unit of flow can enter on at most one edge and can leave on at most one edge. Then one unit of flpw enters $u$ if and only if there is exactly one vertex $v \in R$ such that $f(u,v) = 1$, and at most one edge leaving each $u \in L$ carries positive flow. A symmetric proof can be made for each $v \in R$ Thus the set M is a matching.

Then the linear programming problem could be defined as follows:

\begin{equation}
\begin{aligned}
maximize& \\
& \sum_{v \in L} f_{(s,v)}\\
subject \, to&  \\
& f_{(u,v)} <=1 \, for \, each \, u,v \in \{s\} \cup L \cup R \cup \{t\} = V\\ 
& \sum_{v \in V} f_{(v,u)} = \sum_{v \in V} f_{(u,v)} \, for \, each \, u \in L \cup R\\
&f_{(u,v)} >= 0 \, for \,each \, u,v \in V
\end{aligned}
\end{equation}


\section{29.4-3}
% zhigao
\textbf{Question:}
Write down the dual of the maximum-flow linear program, as given in lines
(29.47)â€“(29.50) on page 860. Explain how to interpret this formulation as a
minimum-cut problem.\\
\textbf{Answer:}
Firstly, I need to convert the original formulas to standard form.
We can set a coefficient C that is 1 when \(u=s\) and -1 when \(v=s\).
\[
\begin{aligned}
maximize& \\
&\sum_{u,v \in V} Cfuv, \\
subject \, to& \\
&f_{uv} \leq c(u, v), \quad \text{for each } u, v \in V, \\
&\sum_{v \in V} f_{vu} = \sum_{v \in V} f_{uv}, \quad \text{for each } u \in V \setminus \{s, t\}, \\
&f_{uv} \geq 0, \quad \text{for each } u, v \in V.
\end{aligned}
\]
The second formula can be changed to 
\[
\sum_{v \in V} f_{vu} - \sum_{v \in V} f_{uv} \leq 0 \quad \text{for each } u \in V \setminus \{s, t\}
\]
\[-\sum_{v \in V} f_{vu} + \sum_{v \in V} f_{uv} \leq 0\ \quad \text{for each } u \in V \setminus \{s, t\}\]
Now we can get the dual subject function by the subject function, for capacity constraints and flow conservation, \(y_{uv}\), \(y_u\)(flow conservation for \(u\)) and \(y_v\)(flow conservation for \(v\))can be introduced, 

\[y_{uv}-y_u+y_v \geq C \quad \text{for each } u, v \in V\]
We can split this equation into:
\[y_{uv}-y_u+y_v \geq 0 \quad \text{for each } u, v \in V\setminus \{s, t\}\]
\[y_{sv}+y_v \geq 1 \quad \text{for each } v \in V\setminus \{s\}\]
\[y_{us}-y_u \geq -1 \quad \text{for each } u \in V\setminus \{s\}\]
\[y_{uv} \geq 0, \quad y_u \geq 0,\quad y_v\geq 0\]
The final object function is :
\[minimize \quad \sum_{u,v \in V} c(u,v)y_{uv}\]
From the object function, we can set \(y_{uv}\) as the variable for every edge, if one edge has been "cut", we need to add the capacity to the result. We can also think of \(y_u\) as the attribution of each point(without s and t). These constraints are to ensure that if two points belong to different sets, then edge \(uv\) must be cut.




\section{Linear Programming - B}
\textbf{Question:}
Write an LP in standard form in the plane so that: (1) the feasible region is a convex polygon with 5 edges, (2) the maximum of the LP is 1 and (3) the maximum is achieved on a full edge of the feasible region (and not just a single vertex)\\
% wenshuo
\textbf{Answer:}

\[
\begin{aligned}
Maximize& \\
&z = x_1 + x_2, \\
Subject \, to& \\
& \quad x_1 \geq 0, \\
& \quad x_2 \geq 0, \\
& \quad x_1 + 2x_2 \leq 2, \\
& \quad 2x_1 + x_2 \leq 2, \\
& \quad x_1 - x_2 \leq 1.
\end{aligned}
\]\\
\textbf{Issue Identified:}
$x_1$ = $x_2$ = 1 is a feasible solution and the objective is 2, so the maximum is clearly at least 2 instead of 1.\\
\textbf{Explanation:}
I find that \(x_1 = x_2 = 1\) \textbf{is not a feasible solution} in my LP because it violates some of the constraints. We can check the constraints at \(x_1 = x_2 = 1\):
\begin{itemize}
    \item \(x_1 + 2x_2 \leq 2\):
    \[
    1 + 2 \times 1 = 3 \not\leq 2
    \]
    \item \(2x_1 + x_2 \leq 2\):
    \[
    2 \times 1 + 1 = 3 \not\leq 2
    \]
\end{itemize}
Since both of these constraints are violated, \(x_1 = x_2 = 1\) is \textbf{not feasible}.

However, to eliminate any confusion and to ensure clarity, I have adjusted the LP to prevent such misunderstandings. 
\[
\begin{aligned}
Maximize& \\
&z = x_1 + x_2, \\
Subject \, to& \\
& \quad x_1 \geq 0, \\
& \quad x_2 \geq 0, \\
& \quad x_1 + x_2 \leq 1, \\
& \quad x_1 + 2x_2 \leq 2, \\
& \quad 2x_1 + x_2 \leq 2.
\end{aligned}
\]
\section{Linear Programming - C}
\textbf{Question}
This exercise demonstrates that LP can represent non-linearities (like absolute values). Let f be a function from the set {1,2} to the real numbers. 

Write an LP whose value is $|f(1)|+|f(2)|$, and write the dual to this LP. In your solutions, all the entries in the matrix A and in the vectors b,c must be affine functions in $f(1)$ and $f(2)$; that is, each entry must be of the form $d f(1) + e f(2) + g$ where $d$,$e$,$g$ are real numbers. For example, in dimension n = 3, the vector b can be $(3 f(1), 0, -2f(2)+1)$ but not $(|f(1)|,0,0)$. \\
% jiayi
\textbf{Answer:}
To express the absolute value  $|f(1)|$ and $|f(2)|$,  we import $x$ and $y$ where $x  \geq|f(1)|$ and $y  \geq|f(2)|$ , so the corresponding constraints are: $x \geq f(1), x \geq -f(1), y \geq f(2), y \geq -f(2)$.\\
For convenience, the objective function will be defined as:
$z = x + y$ and the final question will be convert to:\\
\begin{equation}
\begin{aligned}
minimize& \\
& z = x + y\\
subject \, to&  \\
& x \geq f(1)\\
& x \geq -f(1)\\
& y \geq f(2)\\
& y \geq -f(2)\\
& x\geq 0, y \geq 0\\
\end{aligned}
\end{equation}

To get the dual to the LP,  the minimize need to be convert to the maximize, and $Ax \geq b$ also need to be convert to $A^Ty \leq c$.

The dual is:
\begin{equation}
\begin{aligned}
maximize& \\
& z = f(1)(y_{1} - y_{2}) + f(2)(y_{3} - y_{4}) \\
subject \, to&  \\
& y_{1} + y_{2} \leq 1\\
& y_{3} + y_{4} \leq 1\\
& y_{i}\geq 0, 1\leq y \leq 4\\
\end{aligned}
\end{equation}

\section{Randomized Algorithm-1}
\textbf{Question}
For any given key $x$ in $S$, let $d(x)$ be the depth of $x$ in the search tree generated by $RandQS$. Give a lower and an upper bound, as a function of the number of keys n, on the expected value of $d(x)$ such that these bounds are within a constant factor from each other. That is, find a function $f(n)$ and prove that $E[d(x)]=\Theta(f(n))$.

% wanjing
\textbf{Answer}


%Let $S$ be the set of the $n$ keys, and n us the total number of S. Let i be the number of elements smaller than x, then there are $n-i-1$ numbers greater than x. The probability of x being in level k has two cases: when x is the left child of its father, the father is greater than x, and when x is the right child of the father, the father is smaller than x.

Let S be a sorted set of the original number, and we focus on S(x) meaning the x-th largest number in S. Then P(d(S(x))==i) = P(d(father) == i-1) * P(S(x) is selected as the pivot) = P(d(father) == i-1) * 1/(n-i). When the father is smaller than x. Let k be the total levels of the tree, then $2^{k-1} < n <=2^{k}$, and we have

\begin{equation}
\begin{aligned}
P(d(S(x))==i) &= 2^{i-1}/n\\
&1<=i <= k
\end{aligned}
\end{equation}

\begin{equation}
\begin{aligned}
E(d(x)) &= \sum_{i=1}^{k}  i*2^{i-1}/n\\
&<=\sum_{i=1}^{k}  i*2^{i-k-1}\\
&=2^{-k}\sum_{i=1}^{k}i*2^{i-1}\\
&=2^{-k}*(1+(k-1)*2^k)\\
&<=1/n + log(n) - 1
\end{aligned}
\end{equation}

Also we have
\begin{equation}
\begin{aligned}
E(d(x)) &= \sum_{i=1}^{k}  i*2^{i-1}/n\\
&>\sum_{i=1}^{k-1}  i*2^{i-k-1-1}\\
&=2^{-k-1}\sum_{i=1}^{k-1}i*2^{i-1}\\
&=2^{-k-1}*(1+(k-2)*2^(k-1))\\
&>=1/2*(1/n + 1/2*(log(n)-2))
\end{aligned}
\end{equation}


So we have
\begin{equation}
\begin{aligned}
E[d(x)] = \Theta(log(n))\\
\end{aligned}
\end{equation}


\section{Randomized Algorithm-2}
\textbf{Question}
How many runs of randomized contraction do we need to be 99\% sure that a minimum cut is found?
% zhigao
\textbf{Answer}:
Every time we run the randomized contraction, the probability of min-cut is returned is (n is the number of vectors in the graph):
\[P\geq\frac{2}{n(n-1)}\]
So the probability of min-cut is not returned is :
\[P\geq1-\frac{2}{n(n-1)}\]
By t times, this probability is :
\[(1-\frac{2}{n(n-1)})^t\]
We want to ensure 99\% that a minimum cut is found, Hence:
\[(1-\frac{2}{n(n-1)})^t\leq0.01\]
\[=tln(1-\frac{2}{n(n-1)})\leq ln(0.01)\]
\[=t\leq \frac{ln(0.01)}{ln(1-\frac{2}{n(n-1)})}\]
By using the \(1+x\leq e^x \rightarrow ln(1+x)\leq x\), we get:
\[=t\leq \frac{ln(0.01)}{-\frac{2}{n(n-1)}}\]
Finally, If we want to guarantee more than 99\% probability, then the number of times \(t\) needs to satisfy the following condition.
\[
t \geq \frac{4.605 \cdot n(n - 1)}{2}.
\]


\section{Randomized Algorithm-exercises 1.2}
% wenshuo
\textbf{Question:}
Suppose that at each step of our min-cut algorithm, instead of choosing a random edae for contraction we choose two vertices at random and coalesce them into a single vertex. Show that there are inputs on which the probability that this modified algorithm finds a min-cut is exponentially small.\\
\textbf{Answer:}
Consider a complete graph \( K_n \) with \( n \) vertices, where each pair of vertices is connected by an edge. In this graph, the minimum cut is any single edge because removing any edge separates two vertices. Initially, the graph has \( n \) vertices and \( \binom{n}{2} \) edges. Each edge corresponds to a valid minimum cut. When two vertices \( u \) and \( v \) are randomly chosen and merged, all edges between \( u \) and \( v \) are eliminated. If \( u \) and \( v \) are endpoints of a minimum cut, that cut is destroyed. The probability of not destroying a specific minimum cut at any given step depends on the choice of \( u \) and \( v \). However, since the algorithm does not focus on edges, it does not systematically preserve cuts. Over many steps, the number of remaining cuts diminishes exponentially. Suppose \( n = 4 \). The graph \( K_4 \) has 6 edges, each corresponding to a minimum cut. Initially, the probability of selecting two vertices \( u \) and \( v \) that do not disrupt a specific cut is high. After merging, the graph is reduced to 3 vertices, and the number of valid cuts shrinks. By the time the graph is reduced to 2 vertices, the probability of preserving any specific minimum cut is negligible. The overall probability of success is exponentially small as \( n \) increases.


\section{Randomized Algorithm-exercises 1.3}
%you may assume that T(n) is the worst case running time of A.
% jiayi
\textbf{Question:}
Exercise 1.3: Consider a Monte Carlo algorithm $A$ for a problem $\Pi$ whose expected running time is at most $T(n)$ on any instance of size $n$ and that produces a correct solution with probability $\gamma(n)$. Suppose further that given a solution to $\Pi$, we can verify its correctness in time $t(n)$. Show how to obtain a Las Vegas algorithm that always gives a correct answer to $\Pi$ and runs in expected time at most $(T(n) + t(n))/\gamma(n)$.\\
\textbf{Answer:}
To convert the Monte Carlo algorithm which may get a wrong answer in a fixed time to a Las Vegas algorithm which always get the correct answer in a uncertain time period, we need to verify the correctness and retry the Monte Carlo algorithm until we get the correct answer.\\
For every time we run the Monte Carlo algorithm and verify the answer, it need $T(n) + t(n)$ time and the probability that the answer is correct is $\gamma(n)$. So according to the property of geometrically distributed, the final expected time that the Las Vegas algorithm get the correct answer to $\Pi$ will be $(T(n) + t(n))/\gamma(n)$.
\end{document}
